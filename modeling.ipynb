{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tabulate import tabulate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model, kernel_ridge\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"../full_dataset.csv\")\n",
    "# Change the datatypes to ints, mostly\n",
    "dtype_dict = {\"week\":\"int\",\n",
    "\"visits_2020\":\"int\",\n",
    "\"postal_code\":\"int\",\n",
    "\"naics_code\":\"int\",\n",
    "\"raw_visitor_counts\":\"int\",\n",
    "\"median_dwell_2020\":\"int\",\n",
    "\"num_visitor_country_of_origin\":\"int\",\n",
    "\"num_visitor_home_cbgs\":\"int\",\n",
    "\"num_related_same_day_brand_2020\":\"int\",\n",
    "\"max_hourly_visits\":\"int\",\n",
    "\"visits_2019\":\"int\",\n",
    "\"distance_from_home_2019\":\"int\",\n",
    "\"median_dwell_2019\":\"int\",\n",
    "\"num_related_same_day_brand_2019\":\"int\",\n",
    "\"change_in_visits\":\"float\",\n",
    "\"visits_2020_lastweek\":\"int\",\n",
    "\"raw_visitor_counts_lastweek\":\"int\",\n",
    "\"median_dwell_2020_lastweek\":\"int\",\n",
    "\"num_visitor_country_of_origin_lastweek\":\"int\",\n",
    "\"num_visitor_home_cbgs_lastweek\":\"int\",\n",
    "\"num_related_same_day_brand_2020_lastweek\":\"int\",\n",
    "\"max_hourly_visits_lastweek\":\"int\",\n",
    "\"visits_2019_lastweek\":\"int\",\n",
    "\"median_dwell_2019_lastweek\":\"int\",\n",
    "\"num_related_same_day_brand_2019_lastweek\":\"int\",\n",
    "\"change_in_visits_lastweek\":\"float\",\n",
    "\"visits_2019_nextweek\":\"int\",\n",
    "\"median_dwell_2019_nextweek\":\"int\",\n",
    "\"num_related_same_day_brand_2019_nextweek\":\"int\",\n",
    "\"target\":\"float\",\n",
    "\"naics_2\":\"str\",\n",
    "\"naics_3\":\"str\",\n",
    "\"naics_4\":\"str\",\n",
    "\"naics_5\":\"str\",\n",
    "\"distance_from_home_2019_missing\":\"int\",\n",
    "\"distance_from_home_2019_missing_lastweek\":\"int\",\n",
    "\"distance_from_home_2019_missing_nextweek\":\"int\",\n",
    "\"distance_from_home_2019_lastweek\":\"int\",\n",
    "\"distance_from_home_2019_nextweek\":\"int\",\n",
    "\"naics_2_num_biz\":\"float\",\n",
    "\"naics_3_num_biz\":\"float\",\n",
    "\"naics_4_num_biz\":\"float\",\n",
    "\"naics_5_num_biz\":\"float\",\n",
    "\"naics_6_num_biz\":\"float\"}\n",
    "\n",
    "data = data.astype(dtype_dict)\n",
    "data.to_csv(\"../full_dataset_ints.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# data = pd.read_csv(\"../full_dataset_ints.csv\")\n",
    "\n",
    "# Drop increases of 500%+ \n",
    "drop_rows = data[data['target']>5].index\n",
    "data = data.drop(drop_rows,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional one-hot encoding - Adds lots of columns but didn't have much benefit for lasso, ridge, or xgb\n",
    "\n",
    "def one_hot_data(data,naics_cols):\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    enc.fit(data[naics_cols])\n",
    "    onehotlabels = enc.transform(data[naics_cols]).toarray()\n",
    "    one_hot_col_names = []\n",
    "    for lvl in enc.categories_:\n",
    "        [one_hot_col_names.append(\"naics_\"+str(i)) for i in lvl]\n",
    "    one_hot_df = pd.DataFrame(onehotlabels,columns=one_hot_col_names)\n",
    "    data = data.reset_index(drop=True)\n",
    "    new_data = pd.concat([data,one_hot_df],axis=1)\n",
    "    new_data = new_data.drop(naics_cols,axis=1)\n",
    "    new_data = new_data.drop('naics_0',axis=1)\n",
    "    return new_data,one_hot_col_names\n",
    "\n",
    "naics_cols = [\"naics_2\"]#,\"naics_3\",\"naics_4\",\"naics_5\"]\n",
    "data,one_hot_col_names = one_hot_data(data,naics_cols)\n",
    "# Remove naics_0\n",
    "one_hot_col_names = one_hot_col_names[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"visits_2020\",\n",
    "\"naics_code\",\n",
    "\"raw_visitor_counts\",\n",
    "\"median_dwell_2020\",\n",
    "\"num_visitor_country_of_origin\",\n",
    "\"num_visitor_home_cbgs\",\n",
    "\"num_related_same_day_brand_2020\",\n",
    "\"max_hourly_visits\",\n",
    "\"visits_2019\",\n",
    "\"distance_from_home_2019\",\n",
    "\"median_dwell_2019\",\n",
    "\"num_related_same_day_brand_2019\",\n",
    "\"change_in_visits\",\n",
    "\"visits_2020_lastweek\",\n",
    "\"raw_visitor_counts_lastweek\",\n",
    "\"median_dwell_2020_lastweek\",\n",
    "\"num_visitor_country_of_origin_lastweek\",\n",
    "\"num_visitor_home_cbgs_lastweek\",\n",
    "\"num_related_same_day_brand_2020_lastweek\",\n",
    "\"max_hourly_visits_lastweek\",\n",
    "\"visits_2019_lastweek\",\n",
    "\"median_dwell_2019_lastweek\",\n",
    "\"num_related_same_day_brand_2019_lastweek\",\n",
    "\"change_in_visits_lastweek\",\n",
    "\"visits_2019_nextweek\",\n",
    "\"median_dwell_2019_nextweek\",\n",
    "\"num_related_same_day_brand_2019_nextweek\",\n",
    "# \"naics_2\",\n",
    "\"naics_3\",\n",
    "\"naics_4\",\n",
    "\"naics_5\",\n",
    "\"distance_from_home_2019_missing\",\n",
    "\"distance_from_home_2019_missing_lastweek\",\n",
    "\"distance_from_home_2019_missing_nextweek\",\n",
    "\"distance_from_home_2019_lastweek\",\n",
    "\"distance_from_home_2019_nextweek\",\n",
    "\"naics_2_num_biz\",\n",
    "\"naics_3_num_biz\",\n",
    "\"naics_4_num_biz\",\n",
    "\"naics_5_num_biz\",\n",
    "\"naics_6_num_biz\"]\n",
    "\n",
    "scale_cols = [\"visits_2020\",\n",
    "\"naics_code\",\n",
    "\"raw_visitor_counts\",\n",
    "\"median_dwell_2020\",\n",
    "\"num_visitor_country_of_origin\",\n",
    "\"num_visitor_home_cbgs\",\n",
    "\"num_related_same_day_brand_2020\",\n",
    "\"max_hourly_visits\",\n",
    "\"visits_2019\",\n",
    "\"distance_from_home_2019\",\n",
    "\"median_dwell_2019\",\n",
    "\"num_related_same_day_brand_2019\",\n",
    "\"change_in_visits\",\n",
    "\"visits_2020_lastweek\",\n",
    "\"raw_visitor_counts_lastweek\",\n",
    "\"median_dwell_2020_lastweek\",\n",
    "\"num_visitor_country_of_origin_lastweek\",\n",
    "\"num_visitor_home_cbgs_lastweek\",\n",
    "\"num_related_same_day_brand_2020_lastweek\",\n",
    "\"max_hourly_visits_lastweek\",\n",
    "\"visits_2019_lastweek\",\n",
    "\"median_dwell_2019_lastweek\",\n",
    "\"num_related_same_day_brand_2019_lastweek\",\n",
    "\"change_in_visits_lastweek\",\n",
    "\"visits_2019_nextweek\",\n",
    "\"median_dwell_2019_nextweek\",\n",
    "\"num_related_same_day_brand_2019_nextweek\",\n",
    "# \"naics_2\",\n",
    "\"naics_3\",\n",
    "\"naics_4\",\n",
    "\"naics_5\",\n",
    "\"distance_from_home_2019_missing\",\n",
    "\"distance_from_home_2019_missing_lastweek\",\n",
    "\"distance_from_home_2019_missing_nextweek\",\n",
    "\"distance_from_home_2019_lastweek\",\n",
    "\"distance_from_home_2019_nextweek\",\n",
    "\"naics_2_num_biz\",\n",
    "\"naics_3_num_biz\",\n",
    "\"naics_4_num_biz\",\n",
    "\"naics_5_num_biz\",\n",
    "\"naics_6_num_biz\"]\n",
    "\n",
    "[feature_cols.append(c) for c in one_hot_col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Target variance by week\\n\"+\"*\"*25)\n",
    "for week in data['week'].unique():\n",
    "    ind = data['week']==week\n",
    "    print(\"Week {}: {:2.4f}\".format(week,np.var(data['target'][ind])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make week 15 the test set\n",
    "test_data = data[data['week']==15]\n",
    "# Make week 14 the validation set\n",
    "val_data = data[data['week']==14]\n",
    "# Make train everything else\n",
    "train_data = data[data['week']<14]\n",
    "\n",
    "X_test = test_data[feature_cols].copy()\n",
    "y_test = test_data['target'].copy()\n",
    "\n",
    "X_val = val_data[feature_cols].copy()\n",
    "y_val = val_data['target'].copy()\n",
    "\n",
    "X_train = train_data[feature_cols].copy()\n",
    "y_train = train_data['target'].copy()\n",
    "\n",
    "del(data,test_data,val_data,train_data)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance per week\n",
    "print(\"Test variance (Week 15): {:2.4f}\".format(np.var(y_test)))\n",
    "print(\"Validation variance (Week 14): {:2.4f}\".format(np.var(y_val)))\n",
    "print(\"Train variance (Week 10-13: {:2.4f}\".format(np.var(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale everything based on X_train\n",
    "scaler = StandardScaler(with_std=False)\n",
    "# scaler = StandardScaler()\n",
    "scaler.fit(X_train[scale_cols])\n",
    "X_train[scale_cols] = scaler.transform(X_train[scale_cols])\n",
    "X_val[scale_cols] = scaler.transform(X_val[scale_cols])\n",
    "X_test[scale_cols] = scaler.transform(X_test[scale_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To Consider \n",
    "- Normalize features for some models\n",
    "- Should we use time-based folds?\n",
    "- Set a standard scoring function in GridsearchCV?  Otherwise it defers to the individual regressors.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_covid(X,y,params):\n",
    "    reg = linear_model.Lasso(normalize=True)   \n",
    "    cv_reg = GridSearchCV(reg, \n",
    "                          params,\n",
    "                          n_jobs = 4,\n",
    "                          cv=5,\n",
    "                          refit=True)\n",
    "    cv_reg.fit(X,y)\n",
    "    return cv_reg\n",
    "\n",
    "def ridge_covid(X,y,params):\n",
    "    reg = linear_model.Ridge(normalize=True) \n",
    "    cv_reg = GridSearchCV(reg, \n",
    "                          params,\n",
    "                          n_jobs = 4,\n",
    "                          cv=5,\n",
    "                          refit=True)\n",
    "    cv_reg.fit(X,y)\n",
    "    return cv_reg\n",
    "\n",
    "def kernel_ridge_covid(X,y,params):\n",
    "    reg = kernel_ridge.KernelRidge()    \n",
    "    cv_reg = GridSearchCV(reg, \n",
    "                          params,\n",
    "                          n_jobs = 4,\n",
    "                          cv=5,\n",
    "                          refit=True)\n",
    "    cv_reg.fit(X,y)\n",
    "    return cv_reg\n",
    "\n",
    "# ,GradientBoostingRegressor,AdaBoostRegressor\n",
    "def random_forest_covid(X,y,params):\n",
    "    reg = RandomForestRegressor() #oob_score = True?   \n",
    "    cv_reg = GridSearchCV(reg, \n",
    "                          params,\n",
    "                          n_jobs = -1,\n",
    "                          cv=5,\n",
    "                          refit=True)\n",
    "    cv_reg.fit(X,y)\n",
    "    return cv_reg\n",
    "\n",
    "def gradient_boosting_covid(X,y,params):\n",
    "    reg = GradientBoostingRegressor(n_estimators=100,learning_rate=.1,subsample=1.)     \n",
    "    cv_reg = GridSearchCV(reg, \n",
    "                          params,\n",
    "                          n_jobs = -1,\n",
    "                          cv=5,\n",
    "                          refit=True)\n",
    "    cv_reg.fit(X,y)\n",
    "    return cv_reg\n",
    "\n",
    "def adaboost_covid(X,y,params):\n",
    "    reg = AdaBoostRegressor(n_estimators=200)     \n",
    "    cv_reg = GridSearchCV(reg, \n",
    "                          params,\n",
    "                          n_jobs = -1,\n",
    "                          cv=5,\n",
    "                          refit=True)\n",
    "    cv_reg.fit(X,y)\n",
    "    return cv_reg\n",
    "\n",
    "def mlp_covid(X,y,params):\n",
    "    reg = MLPRegressor(hidden_layer_sizes = (2,40))     \n",
    "    cv_reg = GridSearchCV(reg, \n",
    "                          params,\n",
    "                          n_jobs = -1,\n",
    "                          cv=5,\n",
    "                          refit=True)\n",
    "    cv_reg.fit(X,y)\n",
    "    return cv_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def evaluate(reg_list,X_val,y_val):\n",
    "    '''\n",
    "    Inputs:\n",
    "        reg_list: list of 2-tuples (reg,name)\n",
    "        X_val: array/DataFrame of features\n",
    "        y_val: array/series of labels\n",
    "    \n",
    "    Output:\n",
    "        score_df: DF with model name and metrics for each model on validation set\n",
    "    '''\n",
    "    score_df = pd.DataFrame(columns=['Model','MSE','MAE','r2'])\n",
    "    for reg in reg_list:\n",
    "        mse = mean_squared_error(y_val,reg[0].predict(X_val))\n",
    "        mae = mean_absolute_error(y_val,reg[0].predict(X_val))\n",
    "        r2 = r2_score(y_val,reg[0].predict(X_val))\n",
    "        score_df = score_df.append({'Model':reg[1],'MSE':mse,'MAE':mae,'r2':r2},ignore_index=True)\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_params = {'alpha':(1e-9,1e-8,1e-7,1e-6,1e-5)}\n",
    "\n",
    "ridge_params = {'alpha':(1e-9,1e-8,1e-7,1e-6,1e-5)}\n",
    "\n",
    "random_forest_params = {'n_estimators':(100,500),\n",
    "                         'max_depth':(None,10)}\n",
    "\n",
    "gradient_boosting_params = {'n_estimators':(100,500,1000),\n",
    "#                             'learning_rate':(.01,0.1,1.),\n",
    "#                             'subsample':(0.1,0.5,1.0)\n",
    "                            }\n",
    "\n",
    "adaboost_params = {'n_estimators':(100,500),\n",
    "                   'learning_rate':(1e-3,.1)}\n",
    "\n",
    "mlp_params = {'alpha':(1e-5,1e-3,0.1),\n",
    "              'hidden_layer_sizes':((2,25),(3,40),(2,100),(5,50))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run all the models\n",
    "# lasso = lasso_covid(X_train,y_train,lasso_params)\n",
    "# ridge = ridge_covid(X_train,y_train,ridge_params)\n",
    "a = time.clock()\n",
    "random_forest = random_forest_covid(X_train,y_train,random_forest_params)\n",
    "b = time.clock()\n",
    "print(\"Run time: {:2.4f}seconds\".format(b-a))\n",
    "gradient_boosting = gradient_boosting_covid(X_train,y_train,gradient_boosting_params)\n",
    "c = time.clock()\n",
    "print(\"Run time: {:2.4f}seconds\".format(c-b))\n",
    "adaboost = adaboost_covid(X_train,y_train,adaboost_params)\n",
    "d = time.clock()\n",
    "print(\"Run time: {:2.4f}seconds\".format(d-c))\n",
    "mlp = mlp_covid(X_train,y_train,mlp_params)\n",
    "e = time.clock()\n",
    "print(\"Run time: {:2.4f}seconds\".format(e-d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of best estimators of each type\n",
    "reg_list = [(lasso.best_estimator_,\"Lasso\"),\n",
    "            (ridge.best_estimator_,\"Ridge\"),\n",
    "#             (XGB_reg,\"XGB\"),\n",
    "            (random_forest.best_estimator_,\"Random Forest\"),\n",
    "            (gradient_boosting.best_estimator_,\"Gradient Boosting\"),\n",
    "            (adaboost,\"Adaboost\"),\n",
    "            (mlp,\"MLP\")\n",
    "           ]\n",
    "# Training scores\n",
    "training_score_df = evaluate(reg_list,X_train,y_train)\n",
    "# Validation scores\n",
    "val_score_df = evaluate(reg_list,X_val,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out scores\n",
    "print(\"Training:\")\n",
    "print(tabulate(training_score_df,headers=training_score_df.columns))\n",
    "print(\"\\nValidation:\")\n",
    "print(tabulate(val_score_df,headers=val_score_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost parameter tuning (don't worry about this part)\n",
    "Source: https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_reg = xgb.XGBRegressor(eta= .01, objective='reg:squarederror')\n",
    "XGB_reg.fit(X_train,y_train)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train,label=y_train)\n",
    "dval = xgb.DMatrix(X_val,label=y_val)\n",
    "\n",
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:linear',\n",
    "    'eval_metric':'mae'\n",
    "}\n",
    "num_boost_round = 33 # MAE of 0.136\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dval, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "print(\"Best MAE: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=100,\n",
    "    seed=17,\n",
    "    nfold=5,\n",
    "    metrics={'mae'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the zero-weighted features from lasso\n",
    "for i in range(61):\n",
    "    if abs(lasso.best_estimator_.coef_[i])==0:\n",
    "        print(X_train.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
