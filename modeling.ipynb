{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tabulate import tabulate\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model, kernel_ridge\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"../full_dataset_with_features.csv\")\n",
    "# data = pd.read_csv(\"../full_dataset_ints_old.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 8365\n",
      "2 4760\n",
      "3 3239\n",
      "4 2429\n",
      "5 1916\n",
      "6 1561\n",
      "7 1303\n",
      "8 1089\n",
      "9 937\n",
      "10 813\n",
      "11 720\n",
      "12 639\n",
      "13 563\n",
      "14 510\n",
      "15 463\n",
      "16 423\n",
      "17 388\n",
      "18 358\n",
      "19 334\n",
      "20 315\n",
      "21 300\n",
      "22 279\n",
      "23 263\n",
      "24 250\n"
     ]
    }
   ],
   "source": [
    "# Just FYI, this is how many outliers there are above each threshold.\n",
    "for i in range(1,25):\n",
    "    print(i,np.sum(data['target']>i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'] = [min(t,5) for t in data['target']]\n",
    "data['target'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# data = pd.read_csv(\"../full_dataset_ints.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not using this anymore\n",
    "\n",
    "def one_hot_data(data,naics_cols):\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    enc.fit(data[naics_cols])\n",
    "    onehotlabels = enc.transform(data[naics_cols]).toarray()\n",
    "    one_hot_col_names = []\n",
    "    for lvl in enc.categories_:\n",
    "        [one_hot_col_names.append(\"naics_\"+str(i)) for i in lvl]\n",
    "    one_hot_df = pd.DataFrame(onehotlabels,columns=one_hot_col_names)\n",
    "    data = data.reset_index(drop=True)\n",
    "    new_data = pd.concat([data,one_hot_df],axis=1)\n",
    "    new_data = new_data.drop(naics_cols,axis=1)\n",
    "    new_data = new_data.drop('naics_0',axis=1)\n",
    "    return new_data,one_hot_col_names\n",
    "\n",
    "naics_cols = [\"naics_2\"]#,\"naics_3\",\"naics_4\",\"naics_5\"]\n",
    "data,one_hot_col_names = one_hot_data(data,naics_cols)\n",
    "# Remove naics_0\n",
    "one_hot_col_names = one_hot_col_names[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"visits_2020\",\n",
    "\"naics_code\",\n",
    "\"raw_visitor_counts\",\n",
    "\"median_dwell_2020\",\n",
    "\"num_visitor_country_of_origin\",\n",
    "\"num_visitor_home_cbgs\",\n",
    "\"num_related_same_day_brand_2020\",\n",
    "\"max_hourly_visits\",\n",
    "\"visits_2019\",\n",
    "\"distance_from_home_2019\",\n",
    "\"median_dwell_2019\",\n",
    "\"num_related_same_day_brand_2019\",\n",
    "\"change_in_visits\",\n",
    "\"visits_2020_lastweek\",\n",
    "\"raw_visitor_counts_lastweek\",\n",
    "\"median_dwell_2020_lastweek\",\n",
    "\"num_visitor_country_of_origin_lastweek\",\n",
    "\"num_visitor_home_cbgs_lastweek\",\n",
    "\"num_related_same_day_brand_2020_lastweek\",\n",
    "\"max_hourly_visits_lastweek\",\n",
    "\"visits_2019_lastweek\",\n",
    "\"median_dwell_2019_lastweek\",\n",
    "\"num_related_same_day_brand_2019_lastweek\",\n",
    "\"change_in_visits_lastweek\",\n",
    "\"visits_2019_nextweek\",\n",
    "\"median_dwell_2019_nextweek\",\n",
    "\"num_related_same_day_brand_2019_nextweek\",\n",
    "\"naics_2\",\n",
    "\"naics_3\",\n",
    "\"naics_4\",\n",
    "\"naics_5\",\n",
    "\"distance_from_home_2019_missing\",\n",
    "\"distance_from_home_2019_missing_lastweek\",\n",
    "\"distance_from_home_2019_missing_nextweek\",\n",
    "\"distance_from_home_2019_lastweek\",\n",
    "\"distance_from_home_2019_nextweek\",\n",
    "\"closing_of_public_venues_pct\",\n",
    "\"non-essential_services_closure_pct\",\n",
    "\"school_closure_pct\",\n",
    "\"shelter_in_place_pct\",\n",
    "\"social_distancing_pct\",              \n",
    "\"naics_2_num_biz\",\n",
    "\"naics_3_num_biz\",\n",
    "\"naics_4_num_biz\",\n",
    "\"naics_5_num_biz\",\n",
    "\"naics_6_num_biz\",\n",
    "\"TMIN\",\n",
    "\"TMAX\",\n",
    "\"PRCP\",\n",
    "\"SNOW\",\n",
    "\"WT01\",\n",
    "\"WT02\",\n",
    "\"WT03\",\n",
    "\"WT04\",\n",
    "\"WT06\",\n",
    "\"WT08\",\n",
    "\"WT11\",\n",
    "\"cases\",\n",
    "\"deaths\",\n",
    "\"POPESTIMATE2019\",\n",
    "\"Pop_pct_chg_2019\",\n",
    "\"emp\",\n",
    "\"est\"]\n",
    "\n",
    "scale_cols = [\"visits_2020\",\n",
    "\"naics_code\",\n",
    "\"raw_visitor_counts\",\n",
    "\"median_dwell_2020\",\n",
    "\"num_visitor_country_of_origin\",\n",
    "\"num_visitor_home_cbgs\",\n",
    "\"num_related_same_day_brand_2020\",\n",
    "\"max_hourly_visits\",\n",
    "\"visits_2019\",\n",
    "\"distance_from_home_2019\",\n",
    "\"median_dwell_2019\",\n",
    "\"num_related_same_day_brand_2019\",\n",
    "\"change_in_visits\",\n",
    "\"visits_2020_lastweek\",\n",
    "\"raw_visitor_counts_lastweek\",\n",
    "\"median_dwell_2020_lastweek\",\n",
    "\"num_visitor_country_of_origin_lastweek\",\n",
    "\"num_visitor_home_cbgs_lastweek\",\n",
    "\"num_related_same_day_brand_2020_lastweek\",\n",
    "\"max_hourly_visits_lastweek\",\n",
    "\"visits_2019_lastweek\",\n",
    "\"median_dwell_2019_lastweek\",\n",
    "\"num_related_same_day_brand_2019_lastweek\",\n",
    "\"change_in_visits_lastweek\",\n",
    "\"visits_2019_nextweek\",\n",
    "\"median_dwell_2019_nextweek\",\n",
    "\"num_related_same_day_brand_2019_nextweek\",\n",
    "\"naics_2\",\n",
    "\"naics_3\",\n",
    "\"naics_4\",\n",
    "\"naics_5\",\n",
    "\"distance_from_home_2019_missing\",\n",
    "\"distance_from_home_2019_missing_lastweek\",\n",
    "\"distance_from_home_2019_missing_nextweek\",\n",
    "\"distance_from_home_2019_lastweek\",\n",
    "\"distance_from_home_2019_nextweek\",\n",
    "\"closing_of_public_venues_pct\",\n",
    "\"non-essential_services_closure_pct\",\n",
    "\"school_closure_pct\",\n",
    "\"shelter_in_place_pct\",\n",
    "\"social_distancing_pct\", \n",
    "\"naics_2_num_biz\",\n",
    "\"naics_3_num_biz\",\n",
    "\"naics_4_num_biz\",\n",
    "\"naics_5_num_biz\",\n",
    "\"naics_6_num_biz\",\n",
    "\"TMIN\",\n",
    "\"TMAX\",\n",
    "\"PRCP\",\n",
    "\"SNOW\",\n",
    "\"WT01\",\n",
    "\"WT02\",\n",
    "\"WT03\",\n",
    "\"WT04\",\n",
    "\"WT06\",\n",
    "\"WT08\",\n",
    "\"WT11\",\n",
    "\"cases\",\n",
    "\"deaths\",\n",
    "\"POPESTIMATE2019\",\n",
    "\"Pop_pct_chg_2019\",\n",
    "\"emp\",\n",
    "\"est\"]\n",
    "\n",
    "# [feature_cols.append(c) for c in one_hot_col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variance by week\n",
      "*************************\n",
      "Week 10: 0.8027\n",
      "Week 11: 0.5826\n",
      "Week 12: 0.6199\n",
      "Week 13: 0.5079\n",
      "Week 14: 0.4683\n",
      "Week 15: 0.5488\n"
     ]
    }
   ],
   "source": [
    "print(\"Target variance by week\\n\"+\"*\"*25)\n",
    "for week in data['week'].unique():\n",
    "    ind = data['week']==week\n",
    "    print(\"Week {}: {:2.4f}\".format(week,np.var(data['target'][ind])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make week 15 the test set\n",
    "test_data = data[data['week']==15]\n",
    "# Make week 14 the validation set\n",
    "val_data = data[data['week']==14]\n",
    "# Make train everything else\n",
    "train_data = data[data['week']<14]\n",
    "\n",
    "X_test = test_data[feature_cols].copy()\n",
    "y_test = test_data['target'].copy()\n",
    "\n",
    "X_val = val_data[feature_cols].copy()\n",
    "y_val = val_data['target'].copy()\n",
    "\n",
    "X_train = train_data[feature_cols].copy()\n",
    "y_train = train_data['target'].copy()\n",
    "\n",
    "del(data,test_data,val_data,train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test variance (Week 15): 0.5488\n",
      "Validation variance (Week 14): 0.4683\n",
      "Train variance (Week 10-13: 0.6360\n"
     ]
    }
   ],
   "source": [
    "# Variance per week\n",
    "print(\"Test variance (Week 15): {:2.4f}\".format(np.var(y_test)))\n",
    "print(\"Validation variance (Week 14): {:2.4f}\".format(np.var(y_val)))\n",
    "print(\"Train variance (Week 10-13: {:2.4f}\".format(np.var(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale everything based on X_train\n",
    "# scaler = StandardScaler(with_std=False)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[scale_cols])\n",
    "X_train[scale_cols] = scaler.transform(X_train[scale_cols])\n",
    "X_val[scale_cols] = scaler.transform(X_val[scale_cols])\n",
    "X_test[scale_cols] = scaler.transform(X_test[scale_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_covid(X,y,params):\n",
    "    reg = linear_model.Lasso(normalize=True)   \n",
    "    cv_reg = GridSearchCV(reg, \n",
    "                          params,\n",
    "                          n_jobs = 4,\n",
    "                          cv=5,\n",
    "                          refit=True)\n",
    "    cv_reg.fit(X,y)\n",
    "    return cv_reg\n",
    "\n",
    "def ridge_covid(X,y,params):\n",
    "    reg = linear_model.Ridge(normalize=True) \n",
    "    cv_reg = GridSearchCV(reg, \n",
    "                          params,\n",
    "                          n_jobs = 4,\n",
    "                          cv=5,\n",
    "                          refit=True)\n",
    "    cv_reg.fit(X,y)\n",
    "    return cv_reg\n",
    "\n",
    "def random_forest_covid(X,y,params):\n",
    "    reg = RandomForestRegressor(n_estimators=100) #oob_score = True?   \n",
    "    cv_reg = GridSearchCV(reg, \n",
    "                          params,\n",
    "                          n_jobs = -1,\n",
    "                          cv=5,\n",
    "                          refit=True)\n",
    "    cv_reg.fit(X,y)\n",
    "    return cv_reg\n",
    "\n",
    "def gradient_boosting_covid(X,y,params):\n",
    "    reg = GradientBoostingRegressor(n_estimators=100,learning_rate=.1,subsample=1.)     \n",
    "    cv_reg = GridSearchCV(reg, \n",
    "                          params,\n",
    "                          n_jobs = -1,\n",
    "                          cv=5,\n",
    "                          refit=True)\n",
    "    cv_reg.fit(X,y)\n",
    "    return cv_reg\n",
    "\n",
    "def adaboost_covid(X,y,params):\n",
    "    reg = AdaBoostRegressor(n_estimators=200)     \n",
    "    cv_reg = GridSearchCV(reg, \n",
    "                          params,\n",
    "                          n_jobs = -1,\n",
    "                          cv=5,\n",
    "                          refit=True)\n",
    "    cv_reg.fit(X,y)\n",
    "    return cv_reg\n",
    "\n",
    "def mlp_covid(X,y,params):\n",
    "    reg = MLPRegressor(hidden_layer_sizes = (2,40))     \n",
    "    cv_reg = GridSearchCV(reg, \n",
    "                          params,\n",
    "                          n_jobs = -1,\n",
    "                          cv=5,\n",
    "                          refit=True)\n",
    "    cv_reg.fit(X,y)\n",
    "    return cv_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def evaluate(reg_list,X_val,y_val):\n",
    "    '''\n",
    "    Inputs:\n",
    "        reg_list: list of 2-tuples (reg,name)\n",
    "        X_val: array/DataFrame of features\n",
    "        y_val: array/series of labels\n",
    "    \n",
    "    Output:\n",
    "        score_df: DF with model name and metrics for each model on validation set\n",
    "    '''\n",
    "    score_df = pd.DataFrame(columns=['Model','MSE','MAE','r2'])\n",
    "    for reg in reg_list:\n",
    "        mse = mean_squared_error(y_val,reg[0].predict(X_val))\n",
    "        mae = mean_absolute_error(y_val,reg[0].predict(X_val))\n",
    "        r2 = r2_score(y_val,reg[0].predict(X_val))\n",
    "        score_df = score_df.append({'Model':reg[1],'MSE':mse,'MAE':mae,'r2':r2},ignore_index=True)\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_params = {'alpha':(1e-7,1e-6,1e-5)}\n",
    "\n",
    "ridge_params = {'alpha':(1e-7,1e-6,1e-5)}\n",
    "\n",
    "random_forest_params = {#'n_estimators':(100,500),\n",
    "                         'max_depth':(None,10)}\n",
    "\n",
    "gradient_boosting_params = {'n_estimators':(1000,2000),\n",
    "#                             'learning_rate':(.01,0.1,1.),\n",
    "#                             'subsample':(0.1,0.5,1.0)\n",
    "                            }\n",
    "\n",
    "adaboost_params = {'n_estimators':(100,500),\n",
    "                   'learning_rate':(1e-3,.1)}\n",
    "\n",
    "mlp_params = {'alpha':(1e-5,1e-3),\n",
    "              'hidden_layer_sizes':((2,40),(3,40),(2,100),(5,50),(8,40))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.clock()\n",
    "mlp = mlp_covid(X_train,y_train,mlp_params)\n",
    "b = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 43.7717seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 762.5617seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Run time: {:2.4f}seconds\".format(b-a))\n",
    "gradient_boosting = gradient_boosting_covid(X_train,y_train,gradient_boosting_params)\n",
    "c = time.clock()\n",
    "print(\"Run time: {:2.4f}seconds\".format(c-b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 99.9015seconds\n"
     ]
    }
   ],
   "source": [
    "adaboost = adaboost_covid(X_train,y_train,adaboost_params)\n",
    "d = time.clock()\n",
    "print(\"Run time: {:2.4f}seconds\".format(d-c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 387.9810seconds\n"
     ]
    }
   ],
   "source": [
    "# Run all the models\n",
    "# lasso = lasso_covid(X_train,y_train,lasso_params)\n",
    "# ridge = ridge_covid(X_train,y_train,ridge_params)\n",
    "\n",
    "random_forest = random_forest_covid(X_train,y_train,random_forest_params)\n",
    "e = time.clock()\n",
    "print(\"Run time: {:2.4f}seconds\".format(e-d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The winning XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, eta=0.2, eval_metric='mae',\n",
       "             gamma=0, importance_type='gain', learning_rate=0.1,\n",
       "             max_delta_step=0, max_depth=9, min_child_weight=8, missing=None,\n",
       "             n_estimators=100, n_jobs=1, nthread=None,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "             subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost\n",
    "xgb_params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':9,\n",
    "    'min_child_weight': 8,\n",
    "    'eta':.2,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective':'reg:squarederror',\n",
    "    'eval_metric':'mae'\n",
    "}\n",
    "XGB_reg = xgb.XGBRegressor(max_depth=9,\n",
    "    min_child_weight= 8,\n",
    "    eta=.2,\n",
    "    subsample= 1,\n",
    "    colsample_bytree= 1,\n",
    "    # Other parameters\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='mae')\n",
    "XGB_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of best estimators of each type\n",
    "reg_list = [(lasso.best_estimator_,\"Lasso\"),\n",
    "            (ridge.best_estimator_,\"Ridge\"),\n",
    "            (XGB_reg,\"XGB\"),\n",
    "            (random_forest.best_estimator_,\"Random Forest\"),\n",
    "            (gradient_boosting.best_estimator_,\"Gradient Boosting\"),\n",
    "            (adaboost.best_estimator_,\"Adaboost\"),\n",
    "            (mlp,\"MLP\")\n",
    "           ]\n",
    "# Training scores\n",
    "training_score_df = evaluate(reg_list,X_train,y_train)\n",
    "# Validation scores\n",
    "val_score_df = evaluate(reg_list,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "    Model                    MSE        MAE        r2\n",
      "--  -----------------  ---------  ---------  --------\n",
      " 0  Lasso              0.486116   0.377819   0.235725\n",
      " 1  Ridge              0.483634   0.376412   0.239628\n",
      " 2  XGB                0.0469147  0.133328   0.92624\n",
      " 3  Random Forest      0.0165139  0.0667723  0.974037\n",
      " 4  Gradient Boosting  0.0867616  0.163647   0.863593\n",
      " 5  Adaboost           0.22611    0.29814    0.644508\n",
      " 6  MLP                0.148042   0.191514   0.767247\n",
      "\n",
      "Validation:\n",
      "    Model                    MSE       MAE        r2\n",
      "--  -----------------  ---------  --------  --------\n",
      " 0  Lasso              0.392031   0.376595  0.162818\n",
      " 1  Ridge              0.391235   0.375471  0.164518\n",
      " 2  XGB                0.0744881  0.13261   0.840931\n",
      " 3  Random Forest      0.0778645  0.133755  0.83372\n",
      " 4  Gradient Boosting  0.081776   0.162672  0.825367\n",
      " 5  Adaboost           0.166288   0.251227  0.644893\n",
      " 6  MLP                0.173936   0.244589  0.62856\n"
     ]
    }
   ],
   "source": [
    "# Print out scores\n",
    "print(\"Training:\")\n",
    "print(tabulate(training_score_df,headers=training_score_df.columns))\n",
    "print(\"\\nValidation:\")\n",
    "print(tabulate(val_score_df,headers=val_score_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "import pickle\n",
    "filename = '../models/lasso_model.sav'\n",
    "pickle.dump(lasso, open(filename, 'wb'))\n",
    "\n",
    "# Loading\n",
    "# load_gb = pickle.load(open('../models/gb_model.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/ridge_model.sav'\n",
    "pickle.dump(ridge, open(filename, 'wb'))\n",
    "filename = '../models/rf_model.sav'\n",
    "pickle.dump(random_forest, open(filename, 'wb'))\n",
    "filename = '../models/gb_model.sav'\n",
    "pickle.dump(gradient_boosting, open(filename, 'wb'))\n",
    "filename = '../models/adaboost_model.sav'\n",
    "pickle.dump(adaboost, open(filename, 'wb'))\n",
    "filename = '../models/mlp_model.sav'\n",
    "pickle.dump(mlp, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133362.9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost parameter tuning (don't worry about this part)\n",
    "Source: https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:0.848544\n",
      "Will train until Test-mae hasn't improved in 10 rounds.\n",
      "[1]\tTest-mae:0.621056\n",
      "[2]\tTest-mae:0.465628\n",
      "[3]\tTest-mae:0.359769\n",
      "[4]\tTest-mae:0.288676\n",
      "[5]\tTest-mae:0.239919\n",
      "[6]\tTest-mae:0.208786\n",
      "[7]\tTest-mae:0.188483\n",
      "[8]\tTest-mae:0.174669\n",
      "[9]\tTest-mae:0.168459\n",
      "[10]\tTest-mae:0.162461\n",
      "[11]\tTest-mae:0.158734\n",
      "[12]\tTest-mae:0.156027\n",
      "[13]\tTest-mae:0.155022\n",
      "[14]\tTest-mae:0.154472\n",
      "[15]\tTest-mae:0.153184\n",
      "[16]\tTest-mae:0.152929\n",
      "[17]\tTest-mae:0.152577\n",
      "[18]\tTest-mae:0.152036\n",
      "[19]\tTest-mae:0.151881\n",
      "[20]\tTest-mae:0.151852\n",
      "[21]\tTest-mae:0.15155\n",
      "[22]\tTest-mae:0.150997\n",
      "[23]\tTest-mae:0.150321\n",
      "[24]\tTest-mae:0.150278\n",
      "[25]\tTest-mae:0.149874\n",
      "[26]\tTest-mae:0.149706\n",
      "[27]\tTest-mae:0.149644\n",
      "[28]\tTest-mae:0.149818\n",
      "[29]\tTest-mae:0.149764\n",
      "[30]\tTest-mae:0.149637\n",
      "[31]\tTest-mae:0.149682\n",
      "[32]\tTest-mae:0.149518\n",
      "Best MAE: 0.15 with 33 rounds\n"
     ]
    }
   ],
   "source": [
    "# XGB_reg = xgb.XGBRegressor(eta= .01, objective='reg:squarederror')\n",
    "# XGB_reg.fit(X_train,y_train)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train[:133300],label=y_train[:133300])\n",
    "dval = xgb.DMatrix(X_train[133300:],label=y_train[133300:])\n",
    "\n",
    "\n",
    "num_boost_round = 33 # MAE of 0.136\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dval, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "print(\"Best MAE: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train[:133300],label=y_train[:133300])\n",
    "dval = xgb.DMatrix(X_val,label=y_val[133300:])\n",
    "\n",
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':9,\n",
    "    'min_child_weight': 8,\n",
    "    'eta':.2,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:squarederror',\n",
    "    'eval_metric':'mae'\n",
    "}\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-mae-mean</th>\n",
       "      <th>train-mae-std</th>\n",
       "      <th>test-mae-mean</th>\n",
       "      <th>test-mae-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.820291</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.821161</td>\n",
       "      <td>0.001964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.607053</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.608826</td>\n",
       "      <td>0.002084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.462569</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.465070</td>\n",
       "      <td>0.002169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.365205</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.368543</td>\n",
       "      <td>0.002735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.301279</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.305738</td>\n",
       "      <td>0.002812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.147847</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.178996</td>\n",
       "      <td>0.001744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.147648</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.179006</td>\n",
       "      <td>0.001710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.147492</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.179028</td>\n",
       "      <td>0.001728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.147315</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.179026</td>\n",
       "      <td>0.001703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.147160</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.179048</td>\n",
       "      <td>0.001694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-mae-mean  train-mae-std  test-mae-mean  test-mae-std\n",
       "0         0.820291       0.000461       0.821161      0.001964\n",
       "1         0.607053       0.000356       0.608826      0.002084\n",
       "2         0.462569       0.000503       0.465070      0.002169\n",
       "3         0.365205       0.000437       0.368543      0.002735\n",
       "4         0.301279       0.000398       0.305738      0.002812\n",
       "..             ...            ...            ...           ...\n",
       "95        0.147847       0.000731       0.178996      0.001744\n",
       "96        0.147648       0.000719       0.179006      0.001710\n",
       "97        0.147492       0.000707       0.179028      0.001728\n",
       "98        0.147315       0.000658       0.179026      0.001703\n",
       "99        0.147160       0.000683       0.179048      0.001694\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=33,\n",
    "    seed=17,\n",
    "    nfold=5,\n",
    "    metrics={'mae'},\n",
    "    )\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the zero-weighted features from lasso\n",
    "for i in range(61):\n",
    "    if abs(lasso.best_estimator_.coef_[i])==0:\n",
    "        print(X_train.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=5, min_child_weight=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/ipykernel_launcher.py:29: FutureWarning: \n",
      "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
      "instead.\n",
      "The behavior of 'argmin' will be corrected to return the positional\n",
      "minimum in the future. For now, use 'series.values.argmin' or\n",
      "'np.argmin(np.array(values))' to get the position of the minimum\n",
      "row.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE 0.184 for 32 rounds\n",
      "CV with max_depth=5, min_child_weight=6\n",
      "\tMAE 0.18367 for 32 rounds\n",
      "CV with max_depth=5, min_child_weight=8\n",
      "\tMAE 0.18391459999999998 for 32 rounds\n",
      "CV with max_depth=7, min_child_weight=4\n",
      "\tMAE 0.18030739999999998 for 32 rounds\n",
      "CV with max_depth=7, min_child_weight=6\n",
      "\tMAE 0.1808206 for 32 rounds\n",
      "CV with max_depth=7, min_child_weight=8\n",
      "\tMAE 0.1803672 for 32 rounds\n",
      "CV with max_depth=9, min_child_weight=4\n",
      "\tMAE 0.1807626 for 31 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tMAE 0.1811182 for 32 rounds\n",
      "CV with max_depth=9, min_child_weight=8\n",
      "\tMAE 0.1800506 for 31 rounds\n",
      "CV with max_depth=11, min_child_weight=4\n",
      "\tMAE 0.1828152 for 30 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\tMAE 0.182646 for 31 rounds\n",
      "CV with max_depth=11, min_child_weight=8\n",
      "\tMAE 0.1827732 for 31 rounds\n",
      "CV with max_depth=13, min_child_weight=4\n",
      "\tMAE 0.185885 for 24 rounds\n",
      "CV with max_depth=13, min_child_weight=6\n",
      "\tMAE 0.1854198 for 19 rounds\n",
      "CV with max_depth=13, min_child_weight=8\n",
      "\tMAE 0.18517499999999998 for 23 rounds\n",
      "Best params: 9, 8, MAE: 0.1800506\n"
     ]
    }
   ],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(5,15,2)\n",
    "    for min_child_weight in range(4,10,2)\n",
    "]\n",
    "\n",
    "# Define initial best params and MAE\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/ipykernel_launcher.py:28: FutureWarning: \n",
      "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
      "instead.\n",
      "The behavior of 'argmin' will be corrected to return the positional\n",
      "minimum in the future. For now, use 'series.values.argmin' or\n",
      "'np.argmin(np.array(values))' to get the position of the minimum\n",
      "row.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE 0.1800506 for 31 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tMAE 0.180634 for 32 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tMAE 0.18107020000000001 for 32 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tMAE 0.18068399999999998 for 32 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tMAE 0.18115940000000003 for 30 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tMAE 0.1812616 for 32 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tMAE 0.18202820000000003 for 31 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tMAE 0.18237399999999998 for 31 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tMAE 0.1825118 for 30 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tMAE 0.18280639999999998 for 31 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tMAE 0.1829424 for 30 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tMAE 0.1831692 for 32 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tMAE 0.18346860000000004 for 24 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tMAE 0.18403260000000002 for 30 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tMAE 0.18462220000000001 for 32 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tMAE 0.1846006 for 28 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.1800506\n"
     ]
    }
   ],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with eta=0.3\n",
      "CPU times: user 1min 10s, sys: 512 ms, total: 1min 10s\n",
      "Wall time: 1min 10s\n",
      "\tMAE 0.1846006 for 28 rounds\n",
      "\n",
      "CV with eta=0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: \n",
      "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
      "instead.\n",
      "The behavior of 'argmin' will be corrected to return the positional\n",
      "minimum in the future. For now, use 'series.values.argmin' or\n",
      "'np.argmin(np.array(values))' to get the position of the minimum\n",
      "row.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 488 ms, total: 1min 12s\n",
      "Wall time: 1min 12s\n",
      "\tMAE 0.1823712 for 32 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "CPU times: user 1min 13s, sys: 516 ms, total: 1min 14s\n",
      "Wall time: 1min 14s\n",
      "\tMAE 0.19541219999999998 for 32 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "CPU times: user 1min 13s, sys: 436 ms, total: 1min 14s\n",
      "Wall time: 1min 14s\n",
      "\tMAE 0.31218899999999994 for 32 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "CPU times: user 1min 12s, sys: 536 ms, total: 1min 13s\n",
      "Wall time: 1min 13s\n",
      "\tMAE 0.8385532 for 32 rounds\n",
      "\n",
      "Best params: 0.2, MAE: 0.1823712\n"
     ]
    }
   ],
   "source": [
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    # Run and time CV\n",
    "    %time cv_results = xgb.cv(params,dtrain,num_boost_round=num_boost_round,seed=42,nfold=5,metrics=['mae'],early_stopping_rounds=10)\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
